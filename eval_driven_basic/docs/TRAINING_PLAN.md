# MedicalGPT ç³»ç»Ÿè®­ç»ƒå­¦ä¹ è®¡åˆ’

> æœ¬æ–‡æ¡£åŸºäº MedicalGPT é¡¹ç›®ï¼Œè¯¦ç»†è¯´æ˜å„è®­ç»ƒé˜¶æ®µã€æ•°æ®é›†æ¥æºã€æ˜¾å­˜éœ€æ±‚ç­‰ä¿¡æ¯ã€‚

---

## ğŸ“‹ è®­ç»ƒé˜¶æ®µæ€»è§ˆ

MedicalGPT å®ç°äº†å®Œæ•´çš„å¤§æ¨¡å‹è®­ç»ƒæµç¨‹ï¼ŒåŒ…å«ä»¥ä¸‹é˜¶æ®µï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MedicalGPT è®­ç»ƒæµç¨‹                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Stage 1 â”‚ â†’ â”‚  Stage 2 â”‚ â†’ â”‚        Stage 3          â”‚   â”‚
â”‚  â”‚    PT    â”‚    â”‚   SFT    â”‚    â”‚  (é€‰æ‹©å…¶ä¸€æˆ–ç»„åˆ)        â”‚   â”‚
â”‚  â”‚ å¢é‡é¢„è®­ç»ƒ â”‚    â”‚ æœ‰ç›‘ç£å¾®è°ƒ â”‚    â”‚                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                                   â”‚  â”‚ RM  â”‚â†’â”‚  PPO    â”‚  â”‚   â”‚
â”‚                                   â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                                   â”‚      RLHFæµç¨‹          â”‚   â”‚
â”‚                                   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚                                   â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                                   â”‚  â”‚ DPO â”‚  â”‚  ORPO   â”‚  â”‚   â”‚
â”‚                                   â”‚  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                                   â”‚      ç›´æ¥åå¥½ä¼˜åŒ–        â”‚   â”‚
â”‚                                   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚   â”‚
â”‚                                   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚   â”‚
â”‚                                   â”‚  â”‚  GRPO   â”‚           â”‚   â”‚
â”‚                                   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚                                   â”‚    çº¯å¼ºåŒ–å­¦ä¹             â”‚   â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ å„é˜¶æ®µè¯¦ç»†è¯´æ˜

### Stage 1: PT (Continue PreTraining) - å¢é‡é¢„è®­ç»ƒ

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | åœ¨æµ·é‡é¢†åŸŸæ–‡æ¡£ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒï¼Œè®©æ¨¡å‹é€‚åº”åŒ»ç–—é¢†åŸŸæ•°æ®åˆ†å¸ƒ |
| **æ˜¯å¦å¿…é¡»** | âŒ å¯é€‰ï¼ˆå¦‚ä½¿ç”¨é€šç”¨æ¨¡å‹ç›´æ¥SFTä¹Ÿå¯ï¼‰ |
| **è„šæœ¬** | `pretraining.py` / `run_pt.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-pt-{model}/` |

#### æ•°æ®é›†æ¥æº
| æ•°æ®é›† | è§„æ¨¡ | é“¾æ¥ | é¡¹ç›®æ”¯æŒ |
|-------|------|------|---------|
| shibing624/medical (PTéƒ¨åˆ†) | åŒ…å«åœ¨240ä¸‡æ¡ä¸­ | [HuggingFace](https://huggingface.co/datasets/shibing624/medical) | âœ… |
| Linly-AI/Chinese-pretraining-dataset | 16GB | [HuggingFace](https://huggingface.co/datasets/Linly-AI/Chinese-pretraining-dataset) | âœ… |
| wikipedia-cn-20230720-filtered | 524MB | [HuggingFace](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered) | âœ… |

#### æ•°æ®æ ¼å¼
```text
# çº¯æ–‡æœ¬æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªæ–‡æ¡£
é«˜è¡€å‹æ˜¯ä¸€ç§å¸¸è§çš„å¿ƒè¡€ç®¡ç–¾ç—…ï¼Œä¸»è¦è¡¨ç°ä¸ºè¡€å‹æŒç»­å‡é«˜...
ç³–å°¿ç—…åˆ†ä¸º1å‹å’Œ2å‹ï¼Œ2å‹ç³–å°¿ç—…å 90%ä»¥ä¸Š...
```
æˆ– JSONL æ ¼å¼ï¼š
```json
{"text": "é«˜è¡€å‹æ˜¯ä¸€ç§å¸¸è§çš„å¿ƒè¡€ç®¡ç–¾ç—…..."}
```

#### æ˜¾å­˜éœ€æ±‚
| æ¨¡å‹è§„æ¨¡ | LoRAè®­ç»ƒ | å…¨å‚è®­ç»ƒ | æ¨èGPU |
|---------|---------|---------|---------|
| 3B | 16GB | 60GB | 2Ã—RTX 4090 |
| 7B | 16GB | 120GB | 2Ã—A100 40GB |
| 13B | 32GB | 240GB | 4Ã—A100 40GB |

---

### Stage 2: SFT (Supervised Fine-tuning) - æœ‰ç›‘ç£å¾®è°ƒ

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | æ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œå¯¹é½æŒ‡ä»¤æ„å›¾ï¼Œæ³¨å…¥é¢†åŸŸçŸ¥è¯† |
| **æ˜¯å¦å¿…é¡»** | âœ… æ ¸å¿ƒæ­¥éª¤ |
| **è„šæœ¬** | `supervised_finetuning.py` / `run_sft.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-sft-{model}/` |

#### æ•°æ®é›†æ¥æº
| æ•°æ®é›† | è§„æ¨¡ | ç±»å‹ | é“¾æ¥ | é¡¹ç›®æ”¯æŒ |
|-------|------|------|------|---------|
| **shibing624/medical** | **240ä¸‡æ¡** | åŒ»ç–— | [HuggingFace](https://huggingface.co/datasets/shibing624/medical) | âœ… |
| shibing624/huatuo_medical_qa_sharegpt | 22ä¸‡æ¡ | åŒ»ç–— | [HuggingFace](https://huggingface.co/datasets/shibing624/huatuo_medical_qa_sharegpt) | âœ… |
| shibing624/sharegpt_gpt4 | 10ä¸‡æ¡ | é€šç”¨å¤šè½® | [HuggingFace](https://huggingface.co/datasets/shibing624/sharegpt_gpt4) | âœ… |
| BelleGroup/train_1M_CN | 100ä¸‡æ¡ | ä¸­æ–‡æŒ‡ä»¤ | [HuggingFace](https://huggingface.co/datasets/BelleGroup/train_1M_CN) | éœ€è½¬æ¢ |
| fnlp/moss-002-sft-data | 116ä¸‡æ¡ | ä¸­æ–‡å¤šè½® | [HuggingFace](https://huggingface.co/datasets/fnlp/moss-002-sft-data) | éœ€è½¬æ¢ |

#### æ•°æ®æ ¼å¼ (ShareGPTæ ¼å¼)
```json
{"conversations":[
  {"from":"human","value":"æ„Ÿå†’äº†æ€ä¹ˆåŠï¼Ÿ"},
  {"from":"gpt","value":"æ„Ÿå†’å»ºè®®å¤šä¼‘æ¯ã€å¤šå–æ°´..."}
]}
```

#### æ˜¾å­˜éœ€æ±‚
| æ¨¡å‹è§„æ¨¡ | LoRA | QLoRA (4bit) | å…¨å‚ | æ¨èGPU |
|---------|------|--------------|------|---------|
| 3B | 16GB | 6GB | 60GB | 1Ã—RTX 3090/4090 |
| 7B | 16GB | 10GB | 120GB | 2Ã—RTX 4090 |
| 13B | 32GB | 20GB | 240GB | 2Ã—A100 40GB |
| 70B | 160GB | 48GB | 600GB | 4Ã—A100 80GB |

---

### Stage 3A: RM (Reward Modeling) - å¥–åŠ±æ¨¡å‹å»ºæ¨¡

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œå­¦ä¹ äººç±»åå¥½ï¼ˆhelpful, honest, harmlessï¼‰ |
| **æ˜¯å¦å¿…é¡»** | âŒ ä»…RLHFæµç¨‹éœ€è¦ |
| **è„šæœ¬** | `reward_modeling.py` / `run_rm.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-rm-{model}/` |

#### æ•°æ®é›†æ¥æº
| æ•°æ®é›† | è§„æ¨¡ | è¯­è¨€ | é“¾æ¥ |
|-------|------|------|------|
| shibing624/medical (Rewardéƒ¨åˆ†) | åŒ…å«åœ¨240ä¸‡æ¡ä¸­ | ä¸­æ–‡ | [HuggingFace](https://huggingface.co/datasets/shibing624/medical) |
| tasksource/oasst1_pairwise_rlhf_reward | 2ä¸‡æ¡ | å¤šè¯­è¨€ | [HuggingFace](https://huggingface.co/datasets/tasksource/oasst1_pairwise_rlhf_reward) |
| Dahoas/full-hh-rlhf | 11ä¸‡æ¡ | è‹±æ–‡ | [HuggingFace](https://huggingface.co/datasets/Dahoas/full-hh-rlhf) |
| liyucheng/zhihu_rlhf_3k | 3åƒæ¡ | ä¸­æ–‡ | [HuggingFace](https://huggingface.co/datasets/liyucheng/zhihu_rlhf_3k) |

#### æ•°æ®æ ¼å¼
```json
{"question": "æ„Ÿå†’äº†æ€ä¹ˆåŠï¼Ÿ", "response_chosen": "å»ºè®®å¤šä¼‘æ¯...(å¥½å›ç­”)", "response_rejected": "å–çƒ­æ°´å°±è¡Œ(å·®å›ç­”)"}
```

#### æ˜¾å­˜éœ€æ±‚
| æ¨¡å‹è§„æ¨¡ | LoRA | æ¨èGPU |
|---------|------|---------|
| 3B | 24GB | 1Ã—RTX 4090 |
| 7B | 32GB | 2Ã—RTX 4090 |
| 13B | 48GB | 2Ã—A100 40GB |

---

### Stage 3B: PPO (Proximal Policy Optimization) - å¼ºåŒ–å­¦ä¹ 

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | ç”¨å¥–åŠ±æ¨¡å‹è®­ç»ƒSFTæ¨¡å‹ï¼Œç”Ÿæˆæ›´ç¬¦åˆäººç±»åå¥½çš„æ–‡æœ¬ |
| **æ˜¯å¦å¿…é¡»** | âŒ RLHFæµç¨‹çš„ç¬¬äºŒæ­¥ |
| **å‰ç½®æ¡ä»¶** | éœ€è¦å…ˆå®Œæˆ RM è®­ç»ƒ |
| **è„šæœ¬** | `ppo_training.py` / `run_ppo.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-ppo-{model}/` |

#### æ•°æ®é›†
PPOè®­ç»ƒå¯å¤ç”¨SFTæ•°æ®é›†ï¼Œä¸»è¦ä½¿ç”¨é—®é¢˜éƒ¨åˆ†ç”Ÿæˆå›ç­”ï¼Œç”±RMæ¨¡å‹æ‰“åˆ†ã€‚

#### æ˜¾å­˜éœ€æ±‚ï¼ˆæœ€é«˜ï¼‰
| æ¨¡å‹è§„æ¨¡ | æ˜¾å­˜éœ€æ±‚ | æ¨èGPU |
|---------|---------|---------|
| 3B | â‰¥80GB | 2Ã—A100 40GB |
| 7B | â‰¥160GB | 2Ã—A100 80GB |
| 13B | â‰¥240GB | 4Ã—A100 80GB |

> âš ï¸ PPOéœ€è¦åŒæ—¶åŠ è½½4ä¸ªæ¨¡å‹ï¼ˆActorã€Criticã€Referenceã€Rewardï¼‰ï¼Œæ˜¾å­˜éœ€æ±‚æé«˜

---

### Stage 3C: DPO (Direct Preference Optimization) - ç›´æ¥åå¥½ä¼˜åŒ–

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | æ— éœ€è®­ç»ƒRMï¼Œç›´æ¥ä»åå¥½æ•°æ®å­¦ä¹ ï¼Œç®€åŒ–RLHFæµç¨‹ |
| **æ˜¯å¦å¿…é¡»** | âŒ å¯é€‰ï¼Œä½†æ¨èï¼ˆæ¯”PPOç®€å•é«˜æ•ˆï¼‰ |
| **è„šæœ¬** | `dpo_training.py` / `run_dpo.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-dpo-{model}/` |

#### æ•°æ®é›†æ¥æº
| æ•°æ®é›† | è§„æ¨¡ | è¯­è¨€ | é“¾æ¥ | é¡¹ç›®æ”¯æŒ |
|-------|------|------|------|---------|
| **shibing624/DPO-En-Zh-20k-Preference** | **2ä¸‡æ¡** | ä¸­è‹±æ–‡ | [HuggingFace](https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference) | âœ… |
| shibing624/medical (DPOéƒ¨åˆ†) | åŒ…å«åœ¨240ä¸‡æ¡ä¸­ | ä¸­æ–‡ | [HuggingFace](https://huggingface.co/datasets/shibing624/medical) | âœ… |

#### æ•°æ®æ ¼å¼
```json
{"question": "...", "response_chosen": "å¥½å›ç­”", "response_rejected": "å·®å›ç­”"}
```

#### æ˜¾å­˜éœ€æ±‚
| æ¨¡å‹è§„æ¨¡ | LoRA | QLoRA (4bit) | æ¨èGPU |
|---------|------|--------------|---------|
| 3B | 24GB | 10GB | 1Ã—RTX 4090 |
| 7B | 32GB | 16GB | 2Ã—RTX 4090 |
| 13B | 64GB | 32GB | 2Ã—A100 40GB |

---

### Stage 3D: ORPO (Odds Ratio Preference Optimization) - æ¯”å€¼æ¯”åå¥½ä¼˜åŒ–

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | ä¸éœ€è¦å‚è€ƒæ¨¡å‹ï¼Œæ•´åˆSFTå’Œå¯¹é½ä¸ºå•ä¸€æ­¥éª¤ |
| **ä¼˜åŠ¿** | ç¼“è§£ç¾éš¾æ€§é—å¿˜é—®é¢˜ |
| **è„šæœ¬** | `orpo_training.py` / `run_orpo.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-orpo-{model}/` |

#### æ•°æ®é›†
ä¸DPOç›¸åŒï¼Œä½¿ç”¨åå¥½æ•°æ®é›†ã€‚

#### æ˜¾å­˜éœ€æ±‚
æ¯”DPOç•¥ä½ï¼ˆä¸éœ€è¦Reference Modelï¼‰ï¼š
| æ¨¡å‹è§„æ¨¡ | LoRA | æ¨èGPU |
|---------|------|---------|
| 3B | 20GB | 1Ã—RTX 4090 |
| 7B | 28GB | 2Ã—RTX 4090 |

---

### Stage 3E: GRPO (Group Relative Policy Optimization) - ç¾¤ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç›®çš„** | çº¯RLæ–¹æ³•ï¼Œå¯ä½“éªŒ"aha moment"ï¼ˆé¡¿æ‚Ÿæ—¶åˆ»ï¼‰ |
| **ç‰¹ç‚¹** | æœ€æ–°æ–¹æ³•ï¼Œæ¥è‡ªDeepSeek-R1è®ºæ–‡ |
| **è„šæœ¬** | `grpo_training.py` / `run_grpo.sh` |
| **è¾“å‡ºç›®å½•** | `outputs-grpo-{model}/` |

#### æ˜¾å­˜éœ€æ±‚
| æ¨¡å‹è§„æ¨¡ | LoRA | æ¨èGPU |
|---------|------|---------|
| 3B | 24GB | 1Ã—RTX 4090 |
| 7B | 40GB | 2Ã—RTX 4090 |

---

## ğŸ“Š æ˜¾å­˜éœ€æ±‚æ±‡æ€»è¡¨

### ä»¥ Qwen2.5-3B ä¸ºä¾‹

| è®­ç»ƒé˜¶æ®µ | LoRA | QLoRA (4bit) | å…¨å‚æ•° | æ¨èGPUé…ç½® |
|---------|------|--------------|--------|------------|
| **PT** | 16GB | 6GB | 60GB | 2Ã—RTX 4090 |
| **SFT** | 16GB | 6GB | 60GB | 1Ã—RTX 3090/4090 |
| **RM** | 24GB | 10GB | 80GB | 2Ã—RTX 4090 |
| **PPO** | 80GB+ | - | 200GB+ | 2Ã—A100 80GB |
| **DPO** | 24GB | 10GB | 80GB | 2Ã—RTX 4090 |
| **ORPO** | 20GB | 8GB | 60GB | 1Ã—RTX 4090 |
| **GRPO** | 24GB | 10GB | 80GB | 2Ã—RTX 4090 |

### é€šç”¨æ˜¾å­˜ä¼°ç®—å…¬å¼

| è®­ç»ƒæ–¹æ³• | ç²¾åº¦ | 7B | 13B | 30B | 70B |
|---------|------|-----|-----|-----|------|
| å…¨å‚æ•° | FP16 | 60GB | 120GB | 300GB | 600GB |
| LoRA | FP16 | 16GB | 32GB | 64GB | 160GB |
| QLoRA | 8bit | 10GB | 20GB | 40GB | 80GB |
| QLoRA | 4bit | 6GB | 12GB | 24GB | 48GB |

---

## ğŸ¯ æ¨èè®­ç»ƒè·¯çº¿

### è·¯çº¿1ï¼šå¿«é€Ÿå…¥é—¨ï¼ˆé€‚åˆå­¦ä¹ éªŒè¯ï¼‰
```
SFT (LoRA, å°æ•°æ®é›†1Kæ¡) â†’ æµ‹è¯•
æ—¶é—´: 2-4å°æ—¶
æ˜¾å­˜: 16GB
è´¹ç”¨: ~30å…ƒ (AutoDL)
```

### è·¯çº¿2ï¼šæ ‡å‡†è®­ç»ƒï¼ˆé€‚åˆå®é™…åº”ç”¨ï¼‰
```
SFT (LoRA, 1ä¸‡æ¡) â†’ DPO (5åƒæ¡) â†’ æµ‹è¯•éƒ¨ç½²
æ—¶é—´: 12-24å°æ—¶
æ˜¾å­˜: 24GB
è´¹ç”¨: ~200å…ƒ
```

### è·¯çº¿3ï¼šå®Œæ•´æµç¨‹ï¼ˆæœ€ä½³æ•ˆæœï¼‰
```
PT (10ä¸‡æ¡) â†’ SFT (5ä¸‡æ¡) â†’ DPO (1ä¸‡æ¡) â†’ æµ‹è¯•éƒ¨ç½²
æ—¶é—´: 48-72å°æ—¶
æ˜¾å­˜: 40GB+
è´¹ç”¨: ~600å…ƒ
```

### è·¯çº¿4ï¼šRLHFå®Œæ•´ç‰ˆï¼ˆç ”ç©¶æ¢ç´¢ï¼‰
```
SFT â†’ RM â†’ PPO â†’ æµ‹è¯•
æ—¶é—´: 48-96å°æ—¶
æ˜¾å­˜: 80GB+
è´¹ç”¨: ~1000å…ƒ
```

---

## ğŸ’» äº‘æœåŠ¡å™¨æ¨èé…ç½®

| æ–¹æ¡ˆ | GPUé…ç½® | ä»·æ ¼ | é€‚åˆé˜¶æ®µ |
|------|--------|------|---------|
| **ç»æµå‹** | 1Ã—RTX 3090 (24GB) | ~5å…ƒ/å°æ—¶ | SFT (LoRA) |
| **æ ‡å‡†å‹** | 2Ã—RTX 4090 (24GB) | ~10å…ƒ/å°æ—¶ | SFT, DPO, RM |
| **æ¨èå‹** | 2Ã—A100 (40GB) | ~18å…ƒ/å°æ—¶ | æ‰€æœ‰é˜¶æ®µ |
| **é«˜é…å‹** | 2Ã—A100 (80GB) | ~30å…ƒ/å°æ—¶ | PPOè®­ç»ƒ |

**æ¨èå¹³å°**: AutoDLã€æ’æºäº‘ã€é˜¿é‡Œäº‘PAI

---

## ğŸ“ é¡¹ç›®æ•°æ®é›†å®Œæ•´æ¥æº

### åŒ»ç–—é¢†åŸŸï¼ˆæ ¸å¿ƒï¼‰
| æ•°æ®é›†åç§° | è§„æ¨¡ | ç”¨é€” | é“¾æ¥ |
|-----------|------|------|------|
| shibing624/medical | 240ä¸‡æ¡ | PT+SFT+RM | [Link](https://huggingface.co/datasets/shibing624/medical) |
| shibing624/huatuo_medical_qa_sharegpt | 22ä¸‡æ¡ | SFT | [Link](https://huggingface.co/datasets/shibing624/huatuo_medical_qa_sharegpt) |
| FreedomIntelligence/HuatuoGPT-sft-data-v1 | 22ä¸‡æ¡ | SFT | [Link](https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT-sft-data-v1) |

### é€šç”¨æ•°æ®é›†
| æ•°æ®é›†åç§° | è§„æ¨¡ | ç”¨é€” | é“¾æ¥ |
|-----------|------|------|------|
| shibing624/sharegpt_gpt4 | 10ä¸‡æ¡ | SFT | [Link](https://huggingface.co/datasets/shibing624/sharegpt_gpt4) |
| BelleGroup/train_1M_CN | 100ä¸‡æ¡ | SFT | [Link](https://huggingface.co/datasets/BelleGroup/train_1M_CN) |
| shibing624/DPO-En-Zh-20k-Preference | 2ä¸‡æ¡ | DPO | [Link](https://huggingface.co/datasets/shibing624/DPO-En-Zh-20k-Preference) |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹å‘½ä»¤

```bash
# 1. ç¯å¢ƒå‡†å¤‡
export HF_ENDPOINT=https://hf-mirror.com
pip install -r requirements.txt

# 2. SFTè®­ç»ƒ (å•å¡)
CUDA_VISIBLE_DEVICES=0 python supervised_finetuning.py \
    --model_name_or_path Qwen/Qwen2.5-3B-Instruct \
    --train_file_dir ./data/finetune \
    --use_peft True \
    --output_dir outputs-sft

# 3. DPOè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0 python dpo_training.py \
    --model_name_or_path outputs-sft \
    --train_file_dir ./data/reward \
    --use_peft True \
    --output_dir outputs-dpo

# 4. åˆå¹¶LoRAæƒé‡
python merge_peft_adapter.py \
    --base_model Qwen/Qwen2.5-3B-Instruct \
    --lora_model outputs-dpo \
    --output_dir medical-gpt-final
```

---

## ğŸ“ è®­ç»ƒæ£€æŸ¥æ¸…å•

- [ ] ç¡®è®¤GPUæ˜¾å­˜è¶³å¤Ÿ
- [ ] å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆæ ¼å¼æ­£ç¡®ï¼‰
- [ ] è®¾ç½®HuggingFaceé•œåƒ
- [ ] å®‰è£…æ‰€æœ‰ä¾èµ–
- [ ] é…ç½®è®­ç»ƒå‚æ•°
- [ ] å¼€å¯TensorBoardç›‘æ§
- [ ] è®¾ç½®checkpointä¿å­˜ç­–ç•¥
- [ ] å‡†å¤‡éªŒè¯é—®é¢˜æµ‹è¯•

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¥æœŸ**: 2024å¹´12æœˆ  
**å‚è€ƒé¡¹ç›®**: [MedicalGPT](https://github.com/shibing624/MedicalGPT)
