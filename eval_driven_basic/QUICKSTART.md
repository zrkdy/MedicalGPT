# è¯„æµ‹é©±åŠ¨è®­ç»ƒ - å¿«é€Ÿå¼€å§‹

> 5åˆ†é’Ÿå¿«é€Ÿäº†è§£å¦‚ä½•ä½¿ç”¨è¯„æµ‹é›†å¬å›æ–¹æ³•è®­ç»ƒ MedicalGPT

---

## ğŸ¯ æ ¸å¿ƒæ€è·¯

é€šè¿‡**è¯„æµ‹é›†å‘é‡å¬å›**ä»æµ·é‡æ•°æ®ä¸­ç­›é€‰æœ€ç›¸å…³çš„è®­ç»ƒæ ·æœ¬ï¼Œæå‡æ¨¡å‹åœ¨ç‰¹å®šè¯„æµ‹æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚

```
è¯„æµ‹é›† â†’ å‘é‡åŒ– â†’ å¬å›ç›¸å…³è®­ç»ƒæ•°æ® â†’ åˆå¹¶è®­ç»ƒ â†’ è¯„æµ‹éªŒè¯
```

---

## âš¡ ä¸€é”®å¯åŠ¨

### å‰ç½®å‡†å¤‡

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install zhipuai sentence-transformers

# 2. è®¾ç½® API Key (å¯é€‰ï¼Œä¹Ÿå¯ç”¨æœ¬åœ°æ¨¡å‹)
export ZHIPUAI_API_KEY="your_api_key"

# 3. è®¾ç½® HuggingFace é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

### ä¸€é”®è¿è¡Œ

```bash
# æ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆè‡ªåŠ¨åŒ–ï¼‰
bash scripts/quick_start_eval_driven.sh
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆï¼š
1. âœ… ä¸‹è½½ CEval åŒ»ç–—è¯„æµ‹é›†
2. âœ… å‘é‡åŒ–è¯„æµ‹é›†
3. âœ… å‘é‡åŒ–è®­ç»ƒæ•°æ®
4. âœ… å¬å›ç›¸å…³æ•°æ®
5. âœ… åˆå¹¶ä¸ºè®­ç»ƒé›†
6. âœ… å¯åŠ¨ SFT è®­ç»ƒ

---

## ğŸ“ åˆ†æ­¥æ‰§è¡Œ

### Step 1: ä¸‹è½½è¯„æµ‹é›†

```bash
python scripts/download_ceval.py
```

è¾“å‡º: `data/eval_benchmark/` åŒ…å«åŒ»ç–—ç›¸å…³è¯„æµ‹é›†

### Step 2: å‘é‡åŒ–è¯„æµ‹é›†

```bash
python scripts/vectorize_eval_dataset.py \
    --input_dir data/eval_benchmark \
    --output_dir data/eval_vectorized \
    --model_name glm-embedding-3
```

### Step 3: å‘é‡åŒ–è®­ç»ƒæ•°æ®

```bash
# æ–¹å¼1: ä½¿ç”¨ HuggingFace æ•°æ®é›†
python scripts/vectorize_training_dataset.py \
    --dataset_name shibing624/medical \
    --output_file data/train_vectorized/medical_vectorized.jsonl \
    --max_samples 100000

# æ–¹å¼2: ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
python scripts/vectorize_training_dataset.py \
    --dataset_name data/finetune/my_data.jsonl \
    --output_file data/train_vectorized/my_data_vectorized.jsonl
```

### Step 4: å¬å›ç›¸å…³æ•°æ®

```bash
python scripts/recall_relevant_data.py \
    --eval_vectors data/eval_vectorized \
    --train_vectors data/train_vectorized/medical_vectorized.jsonl \
    --output_dir data/recalled_data \
    --top_k 50 \
    --similarity_threshold 0.75
```

### Step 5: åˆå¹¶æ•°æ®

```bash
python scripts/merge_recalled_data.py \
    --input_dir data/recalled_data \
    --output_file data/finetune/medical_eval_driven.jsonl \
    --format sharegpt
```

### Step 6: è®­ç»ƒ

```bash
# å•å¡è®­ç»ƒ
bash scripts/run_sft_eval_driven.sh

# å¤šå¡è®­ç»ƒï¼ˆ2Ã—RTX 3090ï¼‰
CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 supervised_finetuning.py \
    --model_name_or_path Qwen/Qwen2.5-3B-Instruct \
    --train_file_dir data/finetune/medical_eval_driven.jsonl \
    --per_device_train_batch_size 2 \
    --gradient_accumulation_steps 8 \
    --num_train_epochs 3 \
    --output_dir outputs-sft-eval-driven \
    --use_peft True \
    --lora_rank 64 \
    --deepspeed zero2.json
```

### Step 7: è¯„æµ‹

```bash
python scripts/evaluate_model.py \
    --model_path outputs-sft-eval-driven \
    --eval_dir data/eval_benchmark \
    --output_file eval_results.json
```

---

## ğŸ”§ å…³é”®å‚æ•°è°ƒæ•´

### å¬å›å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | æ¨èèŒƒå›´ |
|------|--------|------|---------|
| `--top_k` | 50 | æ¯ä¸ªè¯„æµ‹é—®é¢˜å¬å›çš„æ ·æœ¬æ•° | 30-100 |
| `--similarity_threshold` | 0.75 | æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ | 0.70-0.85 |
| `--max_similarity` | 0.99 | æœ€å¤§ç›¸ä¼¼åº¦ï¼ˆé˜²æ­¢æ³„éœ²ï¼‰ | 0.95-0.99 |

**è°ƒæ•´å»ºè®®**ï¼š
- æ•°æ®é‡å°‘æ—¶ï¼šå¢å¤§ `top_k` å’Œé™ä½ `similarity_threshold`
- è´¨é‡ä¼˜å…ˆæ—¶ï¼šæé«˜ `similarity_threshold` å’Œå‡å° `top_k`
- é˜²æ­¢è¿‡æ‹Ÿåˆï¼šé™ä½ `max_similarity`

### è®­ç»ƒå‚æ•°

| å‚æ•° | å¬å›æ•°æ® | éšæœºæ•°æ® | è¯´æ˜ |
|------|---------|---------|------|
| `learning_rate` | 1e-5 ~ 2e-5 | 2e-5 ~ 5e-5 | å¬å›æ•°æ®ç”¨æ›´å°å­¦ä¹ ç‡ |
| `num_epochs` | 2-3 | 1-2 | é˜²æ­¢è¿‡æ‹Ÿåˆ |
| `lora_rank` | 64-128 | 32-64 | å¬å›æ•°æ®å¯ç”¨æ›´å¤§rank |

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

åŸºäº Qwen2.5-3B-Instructï¼Œä½¿ç”¨è¯„æµ‹å¬å›æ–¹æ³•è®­ç»ƒåï¼š

| è¯„æµ‹æŒ‡æ ‡ | åŸºçº¿ | éšæœºé‡‡æ · | è¯„æµ‹å¬å› | æå‡ |
|---------|-----|---------|---------|------|
| ä¸´åºŠåŒ»å­¦ | 45% | 53% | **62%** | +9% |
| åŸºç¡€åŒ»å­¦ | 49% | 55% | **65%** | +10% |
| åŒ»å¸ˆèµ„æ ¼ | 51% | 59% | **68%** | +9% |

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: å‘é‡åŒ–éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

- **è¯„æµ‹é›†** (çº¦1000æ¡): 1-5åˆ†é’Ÿ
- **è®­ç»ƒæ•°æ®** (10ä¸‡æ¡): 1-2å°æ—¶
- **è®­ç»ƒæ•°æ®** (50ä¸‡æ¡): 6-12å°æ—¶

**ä¼˜åŒ–å»ºè®®**ï¼š
- ä½¿ç”¨æœ¬åœ°æ¨¡å‹ (sentence-transformers) æ›´å¿«
- å¯ç”¨æ‰¹å¤„ç†å’Œå¤šè¿›ç¨‹
- å…ˆç”¨å°æ•°æ®é›†æµ‹è¯•

### Q2: æ²¡æœ‰ GLM API Key æ€ä¹ˆåŠï¼Ÿ

ä½¿ç”¨æœ¬åœ°å…è´¹æ¨¡å‹ï¼š
```bash
--model_name paraphrase-multilingual-MiniLM-L12-v2
```

æ•ˆæœç•¥å·®ï¼Œä½†å®Œå…¨å…è´¹ã€‚

### Q3: å¦‚ä½•é¿å…"è¯„æµ‹é›†ä½œå¼Š"ï¼Ÿ

1. è®¾ç½® `--max_similarity 0.95` è¿‡æ»¤é«˜åº¦ç›¸ä¼¼æ ·æœ¬
2. æ··å…¥ 20-30% éšæœºåŒ»ç–—æ•°æ®
3. ä½¿ç”¨è¯­ä¹‰å¬å›è€Œéå…³é”®è¯åŒ¹é…
4. åœ¨è¯„æµ‹æ—¶æ’é™¤è®­ç»ƒæ•°æ®

### Q4: æ˜¾å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

```bash
# ä½¿ç”¨ QLoRA (4bit)
python supervised_finetuning.py \
    --load_in_4bit True \
    --use_peft True \
    ...

# å‡å° batch size
--per_device_train_batch_size 1 \
--gradient_accumulation_steps 16

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
--gradient_checkpointing True
```

### Q5: å¦‚ä½•å¯¹æ¯”å®éªŒæ•ˆæœï¼Ÿ

```bash
# è®­ç»ƒå¯¹ç…§ç»„ï¼ˆéšæœºé‡‡æ ·ï¼‰
bash scripts/run_sft_random_sample.sh

# è¯„æµ‹ä¸¤ä¸ªæ¨¡å‹
python scripts/evaluate_model.py --model_path outputs-sft-eval-driven
python scripts/evaluate_model.py --model_path outputs-sft-random

# å¯¹æ¯”ç»“æœ
python scripts/compare_results.py \
    --result1 eval_results_eval_driven.json \
    --result2 eval_results_random.json
```

---

## ğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶ç»“æ„

```
MedicalGPT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ eval_benchmark/                    # åŸå§‹è¯„æµ‹é›†
â”‚   â”‚   â”œâ”€â”€ clinical_medicine.jsonl
â”‚   â”‚   â”œâ”€â”€ basic_medicine.jsonl
â”‚   â”‚   â””â”€â”€ physician.jsonl
â”‚   â”œâ”€â”€ eval_vectorized/                   # å‘é‡åŒ–è¯„æµ‹é›†
â”‚   â”‚   â”œâ”€â”€ clinical_medicine_vectorized.jsonl
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ train_vectorized/                  # å‘é‡åŒ–è®­ç»ƒæ•°æ®
â”‚   â”‚   â””â”€â”€ medical_vectorized.jsonl      # çº¦ 2-5GB
â”‚   â”œâ”€â”€ recalled_data/                     # å¬å›æ•°æ®
â”‚   â”‚   â”œâ”€â”€ recalled_clinical_medicine.jsonl
â”‚   â”‚   â”œâ”€â”€ recall_statistics.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ finetune/
â”‚       â””â”€â”€ medical_eval_driven.jsonl      # æœ€ç»ˆè®­ç»ƒé›†
â””â”€â”€ outputs-sft-eval-driven/               # è®­ç»ƒè¾“å‡º
    â”œâ”€â”€ checkpoint-500/
    â””â”€â”€ ...
```

---

## ğŸš€ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼š

1. **åˆå¹¶æƒé‡**
```bash
python merge_peft_adapter.py \
    --base_model Qwen/Qwen2.5-3B-Instruct \
    --lora_model outputs-sft-eval-driven \
    --output_dir medical-gpt-final
```

2. **éƒ¨ç½²æœåŠ¡**
```bash
python openai_api.py --model_path medical-gpt-final
```

3. **ç»§ç»­ä¼˜åŒ–**
- DPOè®­ç»ƒ: `bash run_dpo.sh`
- PPOè®­ç»ƒ: `bash run_ppo.sh`

---

## ğŸ“š æ›´å¤šæ–‡æ¡£

- å®Œæ•´æ–‡æ¡£: [EVAL_DRIVEN_TRAINING_GUIDE.md](EVAL_DRIVEN_TRAINING_GUIDE.md)
- è®­ç»ƒè®¡åˆ’: [TRAINING_PLAN.md](TRAINING_PLAN.md)
- Qwen2.5è®­ç»ƒ: [TRAINING_GUIDE_Qwen2.5-3B.md](TRAINING_GUIDE_Qwen2.5-3B.md)

---

**ç‰ˆæœ¬**: v1.0  
**æ›´æ–°**: 2024å¹´12æœˆ
