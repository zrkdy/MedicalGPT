#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æœ¬åœ°æ•°æ®å‡†å¤‡è„šæœ¬
åœ¨æœ¬åœ°å®Œæˆæ‰€æœ‰æ•°æ®å‡†å¤‡å·¥ä½œï¼Œç„¶åä¼ è¾“åˆ°æœåŠ¡å™¨è®­ç»ƒ
"""

import os
import sys
import argparse
import subprocess
from pathlib import Path

# è®¾ç½® Windows æ§åˆ¶å° UTF-8 ç¼–ç 
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


def run_command(cmd, description):
    """æ‰§è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¿›åº¦"""
    print("\n" + "=" * 70)
    print(f"ğŸ”„ {description}")
    print("=" * 70)
    print(f"æ‰§è¡Œå‘½ä»¤: {cmd}\n")
    
    result = subprocess.run(cmd, shell=True)
    
    if result.returncode != 0:
        print(f"\nâŒ å¤±è´¥: {description}")
        return False
    
    print(f"\nâœ… å®Œæˆ: {description}")
    return True


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("\n" + "=" * 70)
    print("æ£€æŸ¥ç¯å¢ƒé…ç½®")
    print("=" * 70)
    
    # æ£€æŸ¥ API Key
    api_key = os.getenv("ZHIPUAI_API_KEY")
    if api_key:
        print(f"âœ… ZHIPUAI_API_KEY: {'*' * 20}{api_key[-4:]}")
        use_glm = True
    else:
        print("âš ï¸  æœªè®¾ç½® ZHIPUAI_API_KEYï¼Œå°†ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
        use_glm = False
    
    # æ£€æŸ¥ HF é•œåƒ
    hf_endpoint = os.getenv("HF_ENDPOINT")
    if hf_endpoint:
        print(f"âœ… HF_ENDPOINT: {hf_endpoint}")
    else:
        print("âš ï¸  æœªè®¾ç½® HF_ENDPOINTï¼Œä½¿ç”¨é»˜è®¤åœ°å€")
    
    # æ£€æŸ¥å¿…è¦çš„åŒ…
    try:
        import zhipuai
        print("âœ… zhipuai å·²å®‰è£…")
    except ImportError:
        if use_glm:
            print("âŒ zhipuai æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install zhipuai")
            return False
    
    try:
        import sentence_transformers
        print("âœ… sentence-transformers å·²å®‰è£…")
    except ImportError:
        if not use_glm:
            print("âŒ sentence-transformers æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install sentence-transformers")
            return False
    
    return True, use_glm


def main():
    parser = argparse.ArgumentParser(description="æœ¬åœ°æ•°æ®å‡†å¤‡è„šæœ¬")
    parser.add_argument(
        "--max_samples",
        type=int,
        default=100000,
        help="è®­ç»ƒæ•°æ®æœ€å¤§æ ·æœ¬æ•° (å»ºè®®: æµ‹è¯•10000, æ­£å¼100000-500000)"
    )
    parser.add_argument(
        "--skip_download",
        action="store_true",
        help="è·³è¿‡ä¸‹è½½è¯„æµ‹é›†ï¼ˆå¦‚æœå·²ä¸‹è½½ï¼‰"
    )
    parser.add_argument(
        "--skip_vectorize_eval",
        action="store_true",
        help="è·³è¿‡å‘é‡åŒ–è¯„æµ‹é›†ï¼ˆå¦‚æœå·²å®Œæˆï¼‰"
    )
    parser.add_argument(
        "--skip_vectorize_train",
        action="store_true",
        help="è·³è¿‡å‘é‡åŒ–è®­ç»ƒæ•°æ®ï¼ˆå¦‚æœå·²å®Œæˆï¼‰"
    )
    parser.add_argument(
        "--model_name",
        type=str,
        default=None,
        help="å‘é‡åŒ–æ¨¡å‹ (glm-embedding-3 æˆ– paraphrase-multilingual-MiniLM-L12-v2)"
    )
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("   MedicalGPT æœ¬åœ°æ•°æ®å‡†å¤‡è„šæœ¬")
    print("=" * 70)
    print(f"è®­ç»ƒæ•°æ®æ ·æœ¬æ•°: {args.max_samples}")
    print(f"é¢„è®¡è€—æ—¶: {args.max_samples / 10000 * 0.5:.1f} - {args.max_samples / 10000 * 1.2:.1f} å°æ—¶")
    print("=" * 70)
    
    # æ£€æŸ¥ç¯å¢ƒ
    env_ok, use_glm = check_environment()
    if not env_ok:
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…å¿…è¦çš„ä¾èµ–")
        return 1
    
    # ç¡®å®šå‘é‡åŒ–æ¨¡å‹
    if args.model_name:
        model_name = args.model_name
    else:
        model_name = "glm-embedding-3" if use_glm else "paraphrase-multilingual-MiniLM-L12-v2"
    
    print(f"\nä½¿ç”¨å‘é‡åŒ–æ¨¡å‹: {model_name}")
    
    # ç¡®è®¤ç»§ç»­
    response = input("\næ˜¯å¦ç»§ç»­? (y/n): ")
    if response.lower() != 'y':
        print("å·²å–æ¶ˆ")
        return 0
    
    # Step 1: ä¸‹è½½è¯„æµ‹é›†
    if not args.skip_download:
        if not run_command(
            "python scripts/download_ceval.py",
            "Step 1/5: ä¸‹è½½ CEval åŒ»ç–—è¯„æµ‹é›†"
        ):
            return 1
    else:
        print("\nâ­ï¸  è·³è¿‡: ä¸‹è½½è¯„æµ‹é›†")
    
    # Step 2: å‘é‡åŒ–è¯„æµ‹é›†
    if not args.skip_vectorize_eval:
        if not run_command(
            f"python scripts/vectorize_eval_dataset.py "
            f"--input_dir data/eval_benchmark "
            f"--output_dir data/eval_vectorized "
            f"--model_name {model_name}",
            "Step 2/5: å‘é‡åŒ–è¯„æµ‹é›†"
        ):
            return 1
    else:
        print("\nâ­ï¸  è·³è¿‡: å‘é‡åŒ–è¯„æµ‹é›†")
    
    # Step 3: å‘é‡åŒ–è®­ç»ƒæ•°æ®ï¼ˆæœ€è€—æ—¶ï¼‰
    if not args.skip_vectorize_train:
        print("\n" + "âš ï¸ " * 20)
        print("è­¦å‘Š: è¿™ä¸€æ­¥å¯èƒ½éœ€è¦ {} - {} å°æ—¶".format(
            args.max_samples / 10000 * 0.5,
            args.max_samples / 10000 * 1.2
        ))
        print("å»ºè®®: æ™šä¸Šå¯åŠ¨ï¼Œç¬¬äºŒå¤©æ—©ä¸ŠæŸ¥çœ‹ç»“æœ")
        print("âš ï¸ " * 20)
        
        response = input("\nç¡®è®¤å¼€å§‹å‘é‡åŒ–è®­ç»ƒæ•°æ®? (y/n): ")
        if response.lower() != 'y':
            print("å·²è·³è¿‡ï¼Œå¯ç¨åæ‰‹åŠ¨æ‰§è¡Œ:")
            print(f"  python scripts/vectorize_training_dataset.py --max_samples {args.max_samples}")
        else:
            if not run_command(
                f"python scripts/vectorize_training_dataset.py "
                f"--dataset_name shibing624/medical "
                f"--output_file data/train_vectorized/medical_vectorized.jsonl "
                f"--model_name {model_name} "
                f"--max_samples {args.max_samples}",
                "Step 3/5: å‘é‡åŒ–è®­ç»ƒæ•°æ®"
            ):
                return 1
    else:
        print("\nâ­ï¸  è·³è¿‡: å‘é‡åŒ–è®­ç»ƒæ•°æ®")
    
    # Step 4: å¬å›æ•°æ®
    if not run_command(
        "python scripts/recall_relevant_data.py "
        "--eval_vectors data/eval_vectorized "
        "--train_vectors data/train_vectorized/medical_vectorized.jsonl "
        "--output_dir data/recalled_data "
        "--top_k 50 "
        "--similarity_threshold 0.75",
        "Step 4/5: å¬å›ç›¸å…³æ•°æ®"
    ):
        return 1
    
    # Step 5: åˆå¹¶æ•°æ®
    if not run_command(
        "python scripts/merge_recalled_data.py "
        "--input_dir data/recalled_data "
        "--output_file data/finetune/medical_eval_driven.jsonl "
        "--format sharegpt "
        "--shuffle True",
        "Step 5/5: åˆå¹¶ä¸ºè®­ç»ƒé›†"
    ):
        return 1
    
    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    print("\n" + "=" * 70)
    print("âœ… æœ¬åœ°å‡†å¤‡å®Œæˆï¼")
    print("=" * 70)
    
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    data_files = [
        "data/eval_benchmark/",
        "data/eval_vectorized/",
        "data/train_vectorized/medical_vectorized.jsonl",
        "data/recalled_data/",
        "data/finetune/medical_eval_driven.jsonl"
    ]
    
    for file_path in data_files:
        path = Path(file_path)
        if path.exists():
            if path.is_file():
                size = path.stat().st_size / 1024 / 1024
                print(f"  âœ… {file_path} ({size:.2f} MB)")
            else:
                files = list(path.glob("*"))
                total_size = sum(f.stat().st_size for f in files if f.is_file()) / 1024 / 1024
                print(f"  âœ… {file_path} ({len(files)} æ–‡ä»¶, {total_size:.2f} MB)")
        else:
            print(f"  âŒ {file_path} (ä¸å­˜åœ¨)")
    
    print("\n" + "=" * 70)
    print("ä¸‹ä¸€æ­¥:")
    print("=" * 70)
    print("1. éªŒè¯æ•°æ®: python scripts/verify_data.py")
    print("2. æäº¤å°æ–‡ä»¶åˆ° Git:")
    print("   git add data/eval_benchmark/ data/eval_vectorized/ data/recalled_data/ data/finetune/")
    print("   git commit -m 'Add prepared training data'")
    print("   git push")
    print("\n3. ä¼ è¾“å¤§æ–‡ä»¶åˆ°æœåŠ¡å™¨ (data/train_vectorized/):")
    print("   æ–¹å¼1: ä½¿ç”¨ WinSCP/FileZilla å›¾å½¢ç•Œé¢ä¸Šä¼ ")
    print("   æ–¹å¼2: scp -r data/train_vectorized/ root@server:/root/MedicalGPT/data/")
    print("   æ–¹å¼3: å‹ç¼©åä¸Šä¼  (æ¨è)")
    print("     æœ¬åœ°: tar -czf train_vectorized.tar.gz data/train_vectorized/")
    print("     ä¸Šä¼ : scp train_vectorized.tar.gz root@server:/root/")
    print("     æœåŠ¡å™¨: tar -xzf train_vectorized.tar.gz -C MedicalGPT/")
    print("\n4. åœ¨æœåŠ¡å™¨å¼€å§‹è®­ç»ƒ:")
    print("   bash scripts/run_sft_eval_driven.sh")
    print("=" * 70)
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
