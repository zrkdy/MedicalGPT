#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–æ­¥éª¤1: ä½¿ç”¨å¤§æ¨¡å‹æ ¼å¼åŒ–åŸå§‹è®­ç»ƒæ•°æ®
å‚è€ƒ HealthAI-2025 çš„æ•°æ®è´¨é‡æå‡ç­–ç•¥
"""

import os
import json
import time
from zhipuai import ZhipuAI
from tqdm import tqdm
import argparse

# æ ¼å¼åŒ–Promptï¼ˆæ”¹ç¼–ä¸ºé€šç”¨åŒ»ç–—é—®ç­”æ ¼å¼ï¼‰
FORMAT_PROMPT = '''
ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŒ»ç–—æ•°æ®å¤„ç†åŠ©æ‰‹ã€‚è¯·åˆ†æä»¥ä¸‹åŒ»ç–—å¯¹è¯ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯ã€‚

å¯¹è¯å†…å®¹ï¼š
{content}

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¤„ç†ï¼š
1. åˆ¤æ–­è¿™æ˜¯å¦æ˜¯çœŸå®çš„åŒ»ç–—é—®è¯Šå¯¹è¯ï¼ˆè€Œéç§‘æ™®ã€é—²èŠç­‰ï¼‰
2. å¦‚æœæ˜¯é—®è¯Šï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š
   - æ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼ˆæ€§åˆ«ã€å¹´é¾„ï¼Œå¦‚æœªæåŠåˆ™æ ‡æ³¨"æœªçŸ¥"ï¼‰
   - ä¸»è¯‰ï¼ˆæ ¸å¿ƒç—‡çŠ¶ï¼‰
   - ç°ç—…å²ï¼ˆç—‡çŠ¶è¯¦æƒ…ã€æŒç»­æ—¶é—´ç­‰ï¼‰
   - æ—¢å¾€å²ã€è¿‡æ•å²ç­‰ï¼ˆå¦‚æœ‰æåŠï¼‰
   - åŒ»ç”Ÿçš„è¯Šæ–­æˆ–å»ºè®®

3. å¯¹ä¿¡æ¯å®Œæ•´åº¦æ‰“åˆ†ï¼ˆ0-5åˆ†ï¼‰ï¼š
   - 0-2åˆ†ï¼šåŸºæœ¬ä¿¡æ¯ç¼ºå¤±ä¸¥é‡
   - 3-4åˆ†ï¼šä¸»è¯‰å’Œç°ç—…å²åŸºæœ¬å®Œæ•´
   - 5åˆ†ï¼šä¿¡æ¯éå¸¸è¯¦ç»†å®Œæ•´

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
```json
{{
    "is_consultation": true/false,
    "patient_info": {{
        "gender": "ç”·/å¥³/æœªçŸ¥",
        "age": "å¹´é¾„æˆ–æœªçŸ¥",
        "chief_complaint": "ä¸»è¯‰",
        "history": "ç°ç—…å²",
        "past_history": "æ—¢å¾€å²ï¼ˆå¦‚æ— åˆ™ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰",
        "diagnosis": "åŒ»ç”Ÿè¯Šæ–­æˆ–å»ºè®®"
    }},
    "quality_score": 0-5,
    "reason": "è¯„åˆ†ç†ç”±"
}}
```
'''


class DataFormatter:
    def __init__(self, api_key: str, use_batch: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®æ ¼å¼åŒ–å™¨
        
        Args:
            api_key: æ™ºè°±AI API Key
            use_batch: æ˜¯å¦ä½¿ç”¨æ‰¹é‡æ¨ç†APIï¼ˆæ¨èï¼‰
        """
        self.client = ZhipuAI(api_key=api_key)
        self.use_batch = use_batch
    
    def format_single_record(self, record: dict) -> dict:
        """æ ¼å¼åŒ–å•æ¡è®°å½•ï¼ˆå®æ—¶APIï¼‰"""
        try:
            # æ„å»ºå¯¹è¯å†…å®¹
            if 'conversations' in record:
                # ShareGPTæ ¼å¼
                content = "\n".join([
                    f"{msg['from']}: {msg['value']}" 
                    for msg in record['conversations']
                ])
            elif 'instruction' in record and 'output' in record:
                # Alpacaæ ¼å¼
                content = f"é—®é¢˜: {record['instruction']}\nå›ç­”: {record['output']}"
            else:
                # å°è¯•é€šç”¨å­—æ®µ
                content = record.get('text', str(record))
            
            # è°ƒç”¨API
            response = self.client.chat.completions.create(
                model="glm-4-plus",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŒ»ç–—æ•°æ®å¤„ç†åŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": FORMAT_PROMPT.format(content=content)}
                ],
                temperature=0.1,
                top_p=0.1
            )
            
            # è§£æç»“æœ
            content = response.choices[0].message.content
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            result = json.loads(content[json_start:json_end])
            
            # åˆå¹¶åŸå§‹æ•°æ®
            result['original_id'] = record.get('id', None)
            result['original_content'] = content[:200]  # ä¿ç•™å‰200å­—ç¬¦
            
            return result
            
        except Exception as e:
            print(f"æ ¼å¼åŒ–å¤±è´¥: {e}")
            return None
    
    def build_batch_requests(self, input_file: str, batch_file: str, max_samples: int = None):
        """æ„å»ºæ‰¹é‡æ¨ç†è¯·æ±‚æ–‡ä»¶"""
        print(f"æ„å»ºæ‰¹é‡è¯·ç†è¯·æ±‚...")
        
        with open(input_file, 'r', encoding='utf-8') as fin, \
             open(batch_file, 'w', encoding='utf-8') as fout:
            
            count = 0
            for idx, line in enumerate(tqdm(fin, desc='æ„å»ºè¯·æ±‚')):
                if max_samples and count >= max_samples:
                    break
                
                try:
                    data = json.loads(line)
                    
                    # æå–å†…å®¹
                    if 'conversations' in data:
                        content = "\n".join([
                            f"{msg['from']}: {msg['value']}" 
                            for msg in data['conversations']
                        ])
                    elif 'instruction' in data:
                        content = f"é—®é¢˜: {data['instruction']}\nå›ç­”: {data['output']}"
                    else:
                        content = data.get('text', str(data))
                    
                    # æ„å»ºè¯·æ±‚
                    request = {
                        "custom_id": f"format_{idx}",
                        "method": "POST",
                        "url": "/v4/chat/completions",
                        "body": {
                            "model": "glm-4-plus",
                            "messages": [
                                {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„åŒ»ç–—æ•°æ®å¤„ç†åŠ©æ‰‹ã€‚"},
                                {"role": "user", "content": FORMAT_PROMPT.format(content=content[:2000])}
                            ],
                            "temperature": 0.1,
                            "top_p": 0.1
                        }
                    }
                    
                    fout.write(json.dumps(request, ensure_ascii=False) + '\n')
                    count += 1
                    
                except Exception as e:
                    print(f"è·³è¿‡è¡Œ {idx}: {e}")
                    continue
        
        print(f"âœ… å·²ç”Ÿæˆ {count} æ¡è¯·æ±‚")
        return count
    
    def submit_batch_job(self, batch_file: str) -> str:
        """æäº¤æ‰¹é‡ä»»åŠ¡"""
        print("ä¸Šä¼ æ‰¹é‡æ–‡ä»¶...")
        upload_response = self.client.files.create(
            file=open(batch_file, "rb"),
            purpose="batch"
        )
        file_id = upload_response.id
        print(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ : {file_id}")
        
        print("åˆ›å»ºæ‰¹é‡ä»»åŠ¡...")
        batch_job = self.client.batches.create(
            input_file_id=file_id,
            endpoint="/v4/chat/completions",
            auto_delete_input_file=True,
            metadata={"description": "åŒ»ç–—æ•°æ®æ ¼å¼åŒ–"}
        )
        batch_id = batch_job.id
        print(f"âœ… ä»»åŠ¡å·²åˆ›å»º: {batch_id}")
        
        return batch_id
    
    def wait_batch_completion(self, batch_id: str, output_file: str):
        """ç­‰å¾…æ‰¹é‡ä»»åŠ¡å®Œæˆå¹¶ä¸‹è½½ç»“æœ"""
        print("ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        
        while True:
            status_info = self.client.batches.retrieve(batch_id)
            status = status_info.status
            
            completed = getattr(status_info.request_counts, 'completed', 0)
            total = getattr(status_info.request_counts, 'total', 0)
            
            print(f"çŠ¶æ€: {status} | è¿›åº¦: {completed}/{total}")
            
            if status == 'completed':
                break
            elif status == 'failed':
                print("âŒ ä»»åŠ¡å¤±è´¥")
                return False
            
            time.sleep(10)
        
        print("ä¸‹è½½ç»“æœ...")
        batch_info = self.client.batches.retrieve(batch_id)
        success_content = self.client.files.content(batch_info.output_file_id)
        success_content.write_to_file(output_file)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜: {output_file}")
        return True
    
    def process_batch_results(self, batch_output: str, final_output: str, min_quality: int = 3):
        """å¤„ç†æ‰¹é‡ç»“æœå¹¶è¿‡æ»¤ä½è´¨é‡æ•°æ®"""
        print(f"å¤„ç†æ‰¹é‡ç»“æœ...")
        
        valid_count = 0
        filtered_count = 0
        
        with open(batch_output, 'r', encoding='utf-8') as fin, \
             open(final_output, 'w', encoding='utf-8') as fout:
            
            for line in tqdm(fin, desc='å¤„ç†ç»“æœ'):
                try:
                    response = json.loads(line)
                    
                    if response['response']['status_code'] != 200:
                        continue
                    
                    content = response['response']['body']['choices'][0]['message']['content']
                    
                    # è§£æJSON
                    json_start = content.find('{')
                    json_end = content.rfind('}') + 1
                    result = json.loads(content[json_start:json_end])
                    
                    # è´¨é‡è¿‡æ»¤
                    if (result.get('is_consultation', False) and 
                        result.get('quality_score', 0) >= min_quality):
                        
                        result['custom_id'] = response['custom_id']
                        fout.write(json.dumps(result, ensure_ascii=False) + '\n')
                        valid_count += 1
                    else:
                        filtered_count += 1
                    
                except Exception as e:
                    print(f"è§£æé”™è¯¯: {e}")
                    continue
        
        print(f"âœ… æœ‰æ•ˆæ•°æ®: {valid_count} æ¡")
        print(f"ğŸ—‘ï¸  è¿‡æ»¤æ•°æ®: {filtered_count} æ¡")
        
        return valid_count


def main():
    parser = argparse.ArgumentParser(description="ä¼˜åŒ–æ­¥éª¤1: æ ¼å¼åŒ–è®­ç»ƒæ•°æ®")
    parser.add_argument('--input', required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch_input', default='batch_format_input.jsonl', help='æ‰¹é‡è¯·æ±‚æ–‡ä»¶')
    parser.add_argument('--batch_output', default='batch_format_output.jsonl', help='æ‰¹é‡ç»“æœæ–‡ä»¶')
    parser.add_argument('--max_samples', type=int, help='æœ€å¤§å¤„ç†æ•°é‡')
    parser.add_argument('--min_quality', type=int, default=3, help='æœ€ä½è´¨é‡åˆ†æ•°(0-5)')
    parser.add_argument('--use_batch', type=bool, default=True, help='ä½¿ç”¨æ‰¹é‡API')
    parser.add_argument('--api_key', default=None, help='API Keyï¼ˆæˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼‰')
    
    args = parser.parse_args()
    
    # è·å–API Key
    api_key = args.api_key or os.getenv('ZHIPUAI_API_KEY')
    if not api_key:
        raise ValueError("è¯·è®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ --api_key å‚æ•°")
    
    # åˆå§‹åŒ–
    formatter = DataFormatter(api_key, use_batch=args.use_batch)
    
    if args.use_batch:
        # æ‰¹é‡æ¨¡å¼ï¼ˆæ¨èï¼‰
        print("=" * 70)
        print("ä½¿ç”¨æ‰¹é‡æ¨ç†æ¨¡å¼ï¼ˆæ›´ç¨³å®šã€æ›´ä¾¿å®œï¼‰")
        print("=" * 70)
        
        # æ­¥éª¤1: æ„å»ºè¯·æ±‚
        formatter.build_batch_requests(args.input, args.batch_input, args.max_samples)
        
        # æ­¥éª¤2: æäº¤ä»»åŠ¡
        batch_id = formatter.submit_batch_job(args.batch_input)
        
        # æ­¥éª¤3: ç­‰å¾…å®Œæˆ
        if formatter.wait_batch_completion(batch_id, args.batch_output):
            # æ­¥éª¤4: å¤„ç†ç»“æœ
            formatter.process_batch_results(
                args.batch_output, 
                args.output,
                args.min_quality
            )
    else:
        # å®æ—¶æ¨¡å¼
        print("=" * 70)
        print("ä½¿ç”¨å®æ—¶APIæ¨¡å¼")
        print("=" * 70)
        
        with open(args.input, 'r', encoding='utf-8') as fin, \
             open(args.output, 'w', encoding='utf-8') as fout:
            
            count = 0
            for line in tqdm(fin, desc='æ ¼å¼åŒ–æ•°æ®'):
                if args.max_samples and count >= args.max_samples:
                    break
                
                try:
                    record = json.loads(line)
                    result = formatter.format_single_record(record)
                    
                    if result and result.get('quality_score', 0) >= args.min_quality:
                        fout.write(json.dumps(result, ensure_ascii=False) + '\n')
                        count += 1
                    
                except Exception as e:
                    print(f"å¤„ç†å¤±è´¥: {e}")
                    continue
    
    print("\n" + "=" * 70)
    print("âœ… æ•°æ®æ ¼å¼åŒ–å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()
